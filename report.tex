\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{blindtext, amsmath, comment, subfig, epsfig }
\usepackage{grffile}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage{algorithmic}
\usepackage[utf8]{inputenc}


\title{CS-523 SecretStroll Report}
\author{Manon Michel, Tom Demont}
\date{April 2020}

\begin{document}

\maketitle

\begin{abstract}
    Please report your design, implementation details, and findings of the second project in this report. \\
    You can add references if necessary \cite{article}. \\
    THE REPORT SHOULD NOT EXCEED 5 PAGES.
\end{abstract}

\section{Introduction}

Provide a brief introduction about the aim of the project, and your road-map about the design/implementation for each sub-part.

\section{Attribute-based credential}
Explain how you mapped the system to the attribute based credential. How did you
use the Fiat-Shamir heuristic?

The implementation of \texttt{stroll.py} interprets location subscriptions as a list of strings e.g. $[``cafeteria", ``restaurant", ``laboratory", ``bar", ``dojo"]$. 
We encoded these subscriptions in \texttt{credentials.py} as an AttributeMap, defined as a dictionary with integer indices and Bn values. 

We chose to use the dictionary data structure in order to have better control on the order of the attributes, as the mapping between indices and attributes plays an important role in attribute-based credentials. We map the string representation of a location subscriptions, $sub$, to it's big number value, $attribute$, as follows: 

$attribute = mod(strToBn(sub), ord(G1))$

Where $ord()$ gives the order of a group and $strToBn()$ gives the big number representation of a string. Note that here we take the modulo in order to ensure we have a positive value, which is necessary for the \texttt{jsonpickle} serialization. 

In addition to this, we chose to pad every AttributeMap to the size of the total number of possible subscriptions. The indexes for which there is no user subscription, i.e. no attribute, will contain the big number representation of "None", \textcolor{purple}{$Bn(1315925605)$}. For example, given the following list of possible subscriptions: 

$[``cafeteria", ``restaurant", ``laboratory", ``bar", ``dojo"]$ 

\noindent
and Alice's location subscriptions:  

$[``cafeteria", ``bar", ``dojo"]$ 

\noindent
the corresponding AttributeMap will be:

\noindent
$\{1: Bn(1885434475), \\ 
2: $\textcolor{purple}{$\ Bn(1315925605)$}$, \\
3: $\textcolor{purple}{$\ Bn(1315925605)$}$, \\
4: Bn(120351214630253), \\
5: Bn(1834974328265520539237)\}$


We decided to add this padding in order to avoid information leakage on the user's subscriptions from the size of the corresponding AttributeMap. 

\subsection{Test}
How did you test the system?
You need to test the correct path and at least two failure paths.

\subsection{Evaluation}
Evaluate your ABC: report communication and computation stats (mean and standard
deviation). Report statistic on key generation, issuance, signing, and
verification.

\section{(De)Anonymization of User Trajectories}

\subsection{Privacy Evaluation}
Provide a privacy analysis of the dataset. You should explicitly state your assumptions, adversary
models, methods, and findings.

\subsection{Defences}
Propose a defence that users of the service could deploy to protect their privacy.  You
should state your assumptions, adversary models, and provide an experimental evaluation of your
defences using the datasets and the grid specification. You should also discuss the
privacy-utility trade-offs of your defence.

\section{Cell Fingerprinting via Network Traffic Analysis}

\subsection{Implementation details}
Provide a description of your implementation here. You should provide details on your data collection methods, feature extraction, and classifier training.

\subsection{Evaluation}
Provide an evaluation of your classifier here -- the metrics after 10-fold cross validation.

\subsection{Discussion and Countermeasures}
Comment on your findings here. How well did your classifier perform? What factors could influence its performance? Are there countermeasures against this kind of attack?

\bibliographystyle{IEEEtran}
\bibliography{bib}
\end{document}
